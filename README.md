# aaimc-read-code-refs - AAI MSc at Cranfield 2025 - external references of the reading lists

[ use at your own risk, this page is a list of references mentioned in the course and is NOT an academic material, comments may include my private sentiments, puns or jokes ] 

See the library managed reading lists as primary source of course material, of course. This readme contains just my notes, for private use and to find quickly author's PDFs and github reops. Here I simply go one level deeper thant the published references in the reading list and verify links.

## M01-SLM : Statistical Learning Methods - W02 - 13 OCT 2025

Libary reading list [N-AAI-SLM](https://rl.talis.com/3/cranfield/lists/6600DDA5-EB4C-70FA-0D43-D8F665F9BC18.html?lang=en-GB)

1. Schaum - probability review
   - Some worked out exercises videos are in an iOS or Android app from the publishers [schaums.com](https://www.mheducation.com/highered/campaigns/schaums-outlines.html) - the book is under Mathematics section, the videos of 2-3 worked exercies per chapter for c 1-7, then 1 per 8-10, but none for 11
   - Chapter 11 is a good summary of Bayesian methods, and nice if you like reading the book from the end - I found this one useful
   - This book contains basic probability and statistics material. It is good as a reference and knowledge refresher. Lots of exercises - but there is no literature / references section - again - basic material in a concise form as a foundation, don't expect answers to "why" questions - it is 100 years of stats theory foundametals summarized on 400 pages

2. Murphy - MLP
   - pdf downloadable - the 2012 version [] , the 2025 version (python) - [pml-book](https://probml.github.io/pml-book/book1.html)
   - code in Matlab - the 2012 edition -- [PMTK](https://github.com/probml/pmtk3)
   - code in Python - the 202x edition - [pyprobml](https://github.com/probml/pyprobml)
   - SLM covers chapters 2, 3, 4, 7 (of the 2012 edition)
     - 2 is Probability
     - 3 is Generative models for discrete data
     - 4 is Gaussian models
     - 7 is Linear regression
  - note that there are other related books by K. Murpy, great author and the way of writing IMHO

4. Barber, the barbarian
   - x
   - SLM covers chapters 10, 14, 16
     - 10 is
  - ton of references, and lots of exercises, reading it I get a feeling this is a regurgirated material and not the greates way of exposition, necessary but not my favourite reading, need to find the same content presented in an alternative 

5. ISL - Introduction to Statistical Learning
   - this is a poor-man's verion of the ESL by Hastie Tibshirani from 2001 (or applied version stripped of some rigour and theory)
   - PDFs of the python version and R version of the book - [statlearning.com](https://www.statlearning.com/)
   - code (python and R) - [ISLP_labs on github](https://github.com/intro-stat-learning/ISLP_labs)
   - chapters covered by the SLM module are 3,4,8
     - 3 is Linear Regression
     - 4 is Classification
     - 8 is Tree-Based Methods
